#!/bin/sh
#
# License:      GNU General Public License (GPL)v2
# Description:  Manages ZFS and Lustre on a shared storage
# Written by:   Gabriele Paciucci
# Release Date: 01 June 2016
# Release Version: 0.99
# Copyright Â© 2016, Intel Corporation
#
# This program is free software; you can redistribute it and/or modify 
# it under the terms and conditions of the GNU General Public License,
# version 2, as published by the Free Software Foundation. 
#
# This program is distributed in the hope it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU 
# General Public License for more details.
#
#
# usage: ./LustreZFS {start|stop|status|monitor|validate-all|meta-data}
#
#               OCF parameters are as follows
#               OCF_RESKEY_pool - the pool to import/export
#               OCF_RESKEY_volume - the volume to mount/umount
#               OCF_RESKEY_mountpoint - the mountpoint to use
#######################################################################
# Initialization:

: ${OCF_FUNCTIONS_DIR=${OCF_ROOT}/lib/heartbeat}
. ${OCF_FUNCTIONS_DIR}/ocf-shellfuncs

# Defaults

# Variables used by multiple methods


#######################################################################

# USAGE

usage() {
usage: $0 {start|stop|status|monitor|validate-all|meta-data}
}

# META-DATA

meta_data() {
	cat <<END
<?xml version="1.0"?>
<!DOCTYPE resource-agent SYSTEM "ra-api-1.dtd">
<resource-agent name="LustreZFS">
<version>0.99</version>
<longdesc lang="en">
This script manages ZFS pools and Lustre volumes. The script is able to import and export ZFS pools and mount/umount Lustre.

The standard monitor operation of depth 0 (also known as probe)
checks if the filesystem is mounted and if the pool is imported. 
If you want deeper tests, set OCF_CHECK_LEVEL to one of the following values:

10: perform a zpool get health 

This verify the status of the pool and report in the syslog. In some situation this command 
could hang so we decided to not performe this operation by default.

</longdesc>
<shortdesc lang="en">Lustre and ZFS management</shortdesc>

<parameters>

<parameter name="pool" unique="1" required="1">
<longdesc lang="en">
The name of the ZFS pool to manage.
</longdesc>
<shortdesc lang="en">ZFS pool name</shortdesc>
<content type="string" default="" />
</parameter>

<parameter name="volume" unique="1" required="1">
<longdesc lang="en">
The name of the volume created during the Lustre format on the ZFS pool.
</longdesc>
<shortdesc lang="en">Lustre volume name in the pool</shortdesc>
<content type="string" default="" />
</parameter>

<parameter name="mountpoint" unique="1" required="1">
<longdesc lang="en">
The mount point where the Lustre target will be mounted.
</longdesc>
<shortdesc lang="en">Mount point for Lustre</shortdesc>
<content type="string" default="" />
</parameter>


</parameters>

<actions>
<action name="start"   timeout="300s" />
<action name="stop"    timeout="300s" />
<action name="monitor" depth="0"  timeout="300s" interval="20s" />
<action name="validate-all"  timeout="30s" />
<action name="meta-data"  timeout="5s" />
</actions>
</resource-agent>
END
	exit $OCF_SUCCESS
}

# FUNCTIONS

zpool_is_imported () {
	zpool list -H "$OCF_RESKEY_pool" > /dev/null
}

lustre_is_mounted () {
# Verify if this is consistent
	grep -q "$OCF_RESKEY_mountpoint" /proc/mounts
}

zpool_import () {
	if ! zpool_is_imported; then
		ocf_log info "Starting to import $OCF_RESKEY_pool"

# We start with the assumption that the pool is "protected" by the ZFS's hostid mechanism
# We try first to import without forcing
# If the zpool import return an error, we try again to be sure
# If we got another error, we reboot the other node using stonith_adm -B <name node>
# At this point we can import the pool using the -f option
# The meanings of the options to import are as follows:
#   -f : import even if the pool is marked as imported
#   -o cachefile=none : the import should be temporary

# Try to import clean
			if zpool import -o cachefile=none "$OCF_RESKEY_pool" ; then
				ocf_log info "$OCF_RESKEY_pool imported successfully"
					return $OCF_SUCCESS
			else
				ocf_log err "$OCF_RESKEY_pool import failed with this error $? we are trying again after 5 seconds!"
					sleep 5
					fi
# Try to import clean again JIC

					if zpool import -o cachefile=none "$OCF_RESKEY_pool" ; then
						ocf_log info "$OCF_RESKEY_pool imported successfully"
							return $OCF_SUCCESS
					else
						ocf_log err "$OCF_RESKEY_pool import failed with this error $? we are fencing the other node"
							WhoAmI=$(crm_node -n)
# Valid only in a 2 node cluster
							WhoIsMyPair=$(crm_node -l| grep -v $WhoAmI| cut -f2 -d" ")

							if stonith_admin -B $WhoIsMyPair ; then
								ocf_log info "$WhoIsMyPair fenced successfully"

# Try to import forced after stonith
									sleep 10 

									if zpool import -f -o cachefile=none "$OCF_RESKEY_pool" ; then
										ocf_log info "$OCF_RESKEY_pool imported successfully"
											return $OCF_SUCCESS
									else
										ocf_log err "$OCF_RESKEY_pool FORCED import failed with this error $?. Trying again after 5 sec."
											sleep 10
											if zpool import -f -o cachefile=none "$OCF_RESKEY_pool" ; then
												ocf_log info "$OCF_RESKEY_pool imported successfully"
													return $OCF_SUCCESS
											else
												ocf_log err "$OCF_RESKEY_pool FORCED import failed with this error $? for the SECOND time. Manual operation is needed"
													return $OCF_ERR_GENERIC
													fi									fi



							else
								ocf_log err "$WhoIsMyPair fenced failed with this error $? Please contact the support, safe import is not possible"
									return $OCF_ERR_GENERIC

									fi

									fi
									fi
}

zpool_export () {
	if zpool_is_imported; then
		ocf_log info "Starting to export $OCF_RESKEY_pool"

# The meanings of the options to export are as follows:
#   -f : export in every case

			if zpool export -f "$OCF_RESKEY_pool" ; then
				ocf_log info "$OCF_RESKEY_pool exported successfully"
					return $OCF_SUCCESS
			else
				ocf_log err "$OCF_RESKEY_pool export failed"
					return $OCF_ERR_GENERIC
					fi
					fi
}


lustre_mount () {
	if ! lustre_is_mounted; then
		ocf_log info "Starting to mount $OCF_RESKEY_volume"

# The meanings of the options to export are as follows:
#

			if mount -t lustre "$OCF_RESKEY_pool/$OCF_RESKEY_volume" $OCF_RESKEY_mountpoint ; then

				ocf_log info "$OCF_RESKEY_volume mounted successfully"
					return $OCF_SUCCESS
			else
				ocf_log err "$OCF_RESKEY_volume mount failed"
					return $OCF_ERR_GENERIC
					fi
					fi
}


lustre_umount () {

	if lustre_is_mounted; then
		ocf_log info "Starting to unmount $OCF_RESKEY_volume"

# The meanings of the options to export are as follows:
#  -f : force umount

			if umount -f $OCF_RESKEY_mountpoint; then

				ocf_log info "$OCF_RESKEY_volume unmounted successfully"
					return $OCF_SUCCESS
			else
				ocf_log err "$OCF_RESKEY_volume unmount failed"
					return $OCF_ERR_GENERIC
					fi
					fi
}


zpool_monitor () {

# If the pool is not imported, then we can't monitor its health
	if ! zpool_is_imported; then
		ocf_log warn "$OCF_RESKEY_pool not imported"
			return $OCF_NOT_RUNNING
			fi


			if [ $OCF_CHECK_LEVEL -eq 10 ]; then

##
## ATTENTION zpool can hang in some conditions
# Check the pool status
# Possible status:
#   DEGRADED
#   FAULTED
#   OFFLINE
#   ONLINE
#   REMOVED
#   UNAVAIL


				HEALTH=$(zpool get health $OCF_RESKEY_pool |grep health| awk '{print $3}')
	case "$HEALTH" in
					ONLINE)                 
#to debug ocf_log info "$OCF_RESKEY_pool is $HEALTH"
						return $OCF_SUCCESS
						;;
					DEGRADED)               
						ocf_log warn "$OCF_RESKEY_pool is $HEALTH"
						return $OCF_SUCCESS
						;;
					FAULTED)                
						ocf_log err "$OCF_RESKEY_pool is $HEALTH"
						return $OCF_ERR_GENERIC
						;;
					*)                      
						ocf_log err "$OCF_RESKEY_pool is $HEALTH"
						return $OCF_ERR_GENERIC
						;;
					esac
						fi


						return $OCF_SUCCESS

}


lustre_monitor () {

	if ! lustre_is_mounted; then
		ocf_log err "$OCF_RESKEY_volume is not mounted"
			return $OCF_NOT_RUNNING

	else
# to debug ocf_log info "$OCF_RESKEY_volume is mounted"
		return $OCF_SUCCESS

			fi

}




all_start () {

	zpool_import
		imp_success=$?
		if [ "$imp_success" != "$OCF_SUCCESS" ]; then 
			ocf_log err "$OCF_RESKEY_pool can not be imported with this error: $imp_success"
				return $OCF_ERR_GENERIC
		else
			sleep 5
				lustre_mount
				mnt_success=$?

				if [ "$mnt_success" != "$OCF_SUCCESS" ]; then
					ocf_log err "$OCF_RESKEY_volume can not be mounted with this error: $mnt_success"
						return $OCF_ERR_GENERIC
						fi
						fi

						return $OCF_SUCCESS


}



all_stop () {

	lustre_umount	
		mnt_success=$?
		if [ "$mnt_success" != "$OCF_SUCCESS" ]; then
			ocf_log err "$OCF_RESKEY_volume can not be unmounted with this error: $mnt_success"
				return $OCF_ERR_GENERIC
		else
			sleep 5
				zpool_export 
				exp_success=$?

				if [ "$exp_success" != "$OCF_SUCCESS" ]; then
					ocf_log err "$OCF_RESKEY_volume can not be exported with this error: $exp_success"
						return $OCF_ERR_GENERIC
						fi
						fi

						return $OCF_SUCCESS



}


all_monitor () {

##
## ATTENTION zpool status can hang in some conditions we disable at the moment this test
## in order to find a way to monitor a pool better
##


# if zpool_monitor return OCF_SUCCESS then execute lustre monitoring
	zpool_monitor
		zpool_result=$?

	case "$zpool_result" in
		$OCF_SUCCESS)           lustre_monitor
			lustre_result=$?
			if [ "$lustre_result" ==  $OCF_SUCCESS ]; then	
				return $OCF_SUCCESS
					fi
					return $OCF_NOT_RUNNING
					;;
		$OCF_NOT_RUNNING)       # skip any additional tests and return 
			return $OCF_NOT_RUNNING
			;;
		$OCF_ERR_GENERIC)       # skip any additional tests and return the error
			return $OCF_ERR_GENERIC
			;;
		*)                      ocf_log err "Unexpected result from the zpool_monitor function"
			return $OCF_ERR_GENERIC
			;;
		esac



}

validate () {

# Maybe we can implement some validation
	return $OCF_SUCCESS

}



case $1 in
meta-data)          meta_data;;
start)              all_start;;
stop)               all_stop;;
status|monitor)     all_monitor;;
validate-all)       validate;;
usage)              usage
exit $OCF_SUCCESS
;;
*)                  exit $OCF_ERR_UNIMPLEMENTED;;
esac

exit $?



