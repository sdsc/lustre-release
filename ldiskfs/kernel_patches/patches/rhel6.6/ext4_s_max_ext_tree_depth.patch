Fix ext4_ext_find_extent() to already pre-allocate ext4_ext_path[]
array of the max depth instead of current depth.
This will avoid racy cases of concurrent ext_depth() growth in
current and unsafe implementation with ext4_ext_path[] array
re-[sizing,allocation], even with more recent and related patches
that will be integrated in more recent Kernels.

Index: linux-2.6.32-504.el6.x86_64/fs/ext4/ext4.h
===================================================================
--- linux-2.6.32-504.el6.x86_64.orig/fs/ext4/ext4.h
+++ linux-2.6.32-504.el6.x86_64/fs/ext4/ext4.h
@@ -1147,6 +1147,9 @@
 	unsigned long s_ext_extents;
 #endif
 
+	/* maximum possible extents tree depth, to be computed at mount time */
+	unsigned int s_max_ext_tree_depth;
+
 	/* for buddy allocator */
 	struct ext4_group_info ***s_group_info;
 	struct inode *s_buddy_cache;
Index: linux-2.6.32-504.el6.x86_64/fs/ext4/extents.c
===================================================================
--- linux-2.6.32-504.el6.x86_64.orig/fs/ext4/extents.c
+++ linux-2.6.32-504.el6.x86_64/fs/ext4/extents.c
@@ -699,8 +699,16 @@
 
 	/* account possible depth increase */
 	if (!path) {
-		path = kzalloc(sizeof(struct ext4_ext_path) * (depth + 2),
-				GFP_NOFS);
+		/* during early mount I/Os (internal journal setup, ...)
+		 * s_max_ext_tree_depth may still not be computed
+		 * so if not, revert to old and empirical method */
+		if (EXT4_SB(inode->i_sb)->s_max_ext_tree_depth)
+			path = kzalloc(sizeof(struct ext4_ext_path) *
+				     EXT4_SB(inode->i_sb)->s_max_ext_tree_depth,
+				       GFP_NOFS);
+		else
+			path = kzalloc(sizeof(struct ext4_ext_path) *
+				       (depth + 2), GFP_NOFS);
 		if (!path)
 			return ERR_PTR(-ENOMEM);
 		alloc = 1;
@@ -1915,11 +1923,8 @@
 		/* find extent for this block */
 		down_read(&EXT4_I(inode)->i_data_sem);
 
-		if (path && ext_depth(inode) != depth) {
-			/* depth was changed. we have to realloc path */
-			kfree(path);
-			path = NULL;
-		}
+		/* path of max possible depth will be allocated during
+		 * first pass, so its space can be re-used for each loop */
 
 		path = ext4_ext_find_extent(inode, block, path);
 		if (IS_ERR(path)) {
@@ -2664,8 +2669,16 @@
 			path[k].p_block =
 				le16_to_cpu(path[k].p_hdr->eh_entries)+1;
 	} else {
-		path = kzalloc(sizeof(struct ext4_ext_path) * (depth + 1),
-			       GFP_NOFS);
+		/* during early mount I/Os (internal journal setup, ...)
+		 * s_max_ext_tree_depth may still not be computed
+		 * so if not, revert to old and empirical method */
+		if (EXT4_SB(inode->i_sb)->s_max_ext_tree_depth)
+			path = kzalloc(sizeof(struct ext4_ext_path) *
+				     EXT4_SB(inode->i_sb)->s_max_ext_tree_depth,
+				       GFP_NOFS);
+		else
+			path = kzalloc(sizeof(struct ext4_ext_path) *
+				       (depth + 1), GFP_NOFS);
 		if (path == NULL) {
 			ext4_journal_stop(handle);
 			return -ENOMEM;
@@ -2790,13 +2803,15 @@
  */
 void ext4_ext_init(struct super_block *sb)
 {
+	unsigned long pow;
+
 	/*
 	 * possible initialization would be here
 	 */
 
 	if (EXT4_HAS_INCOMPAT_FEATURE(sb, EXT4_FEATURE_INCOMPAT_EXTENTS)) {
-#if defined(AGGRESSIVE_TEST) || defined(CHECK_BINSEARCH) || defined(EXTENTS_STATS)
-		printk(KERN_INFO "EXT4-fs: file extents enabled");
+		printk(KERN_INFO "EXT4-fs (%s): file extents enabled",
+		       sb->s_id);
 #ifdef AGGRESSIVE_TEST
 		printk(", aggressive tests");
 #endif
@@ -2805,14 +2820,33 @@
 #endif
 #ifdef EXTENTS_STATS
 		printk(", stats");
-#endif
-		printk("\n");
-#endif
-#ifdef EXTENTS_STATS
 		spin_lock_init(&EXT4_SB(sb)->s_ext_stats_lock);
 		EXT4_SB(sb)->s_ext_min = 1 << 30;
 		EXT4_SB(sb)->s_ext_max = 0;
 #endif
+		EXT4_SB(sb)->s_max_ext_tree_depth = 1;
+
+		/* 1st level of extents tree stands in i_data and
+		 * entries stored in tree nodes can be of type ext4_extent
+		 * (leaf node) or ext4_extent_idx (internal node) */
+		pow = (sizeof(((struct ext4_inode_info *)0x0)->i_data) -
+		       sizeof(struct ext4_extent_header)) /
+		      max(sizeof(struct ext4_extent),
+			  sizeof(struct ext4_extent_idx));
+
+		/* compute maximum extents tree depth for a fully populated
+		 * file of max size made of only minimal/1-block extents */
+		while ((sb->s_maxbytes / sb->s_blocksize) > pow) {
+			pow *= (sb->s_blocksize -
+				 sizeof(struct ext4_extent_header)) /
+			       max(sizeof(struct ext4_extent),
+				   sizeof(struct ext4_extent_idx));
+			EXT4_SB(sb)->s_max_ext_tree_depth++;
+		}
+
+		printk(", maximum extents tree depth=%u",
+		       EXT4_SB(sb)->s_max_ext_tree_depth);
+		printk("\n");
 	}
 }
 
@@ -4614,11 +4648,8 @@
 			break;
 		}
 
-		if (ext_depth(inode) != depth) {
-			/* depth was changed. we have to realloc path */
-			kfree(path);
-			path = NULL;
-		}
+		/* path of max possible depth will be allocated during
+		 * first pass, so its space can be re-used for each loop */
 
 		block = cbex.ec_block + cbex.ec_len;
 	}
