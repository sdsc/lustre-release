dqptr_sem is one of the most contenting locks for now each
dquot_initialize and dquot_transfer result in down_write(dqptr_sem).
Let's user inode->i_lock to protect i_dquot pointers. In that case
all users which modified i_dquot simply converted to that lock. But
users who hold the dqptr_sem for read(charge/uncharge methods)
usually looks like follows

down_read(&dqptr_sem)
___charge_quota()
make_quota_dirty(inode->i_dquot) --> may_sleep
up_read(&dquot_sem)

We must drop i_lock before make_quota_dirty or flush_warnings, to
protect dquot from being fried let's grab extra reference for dquot,
and drop it after we have done with dquot object.

Signed-off-by: Dmitry Monakhov <dmonakhov@openvz.org>

 fs/quota/dquot.c   |  164 +++++++++++++++++++++++++++++------------------------
 fs/quota/quota.c   |    6 -
 fs/stat.c          |   15 +++-
 fs/super.c         |    1
 include/linux/fs.h |    2
 5 files changed, 107 insertions(+), 81 deletions(-)

--- linux-2.6.32-279.el6.x86_64/fs/quota/dquot.c	2012-06-14 05:40:59.000000000 +0800
+++ linux-2.6.32-279.el6.x86_64.quota/fs/quota/dquot.c	2013-02-20 18:39:46.212959818 +0800
@@ -83,22 +83,17 @@
 /*
  * There are three quota SMP locks. dq_list_lock protects all lists with quotas
  * and quota formats, dqstats structure containing statistics about the lists
- * dq_data_lock protects data from dq_dqb and also mem_dqinfo structures and
- * also guards consistency of dquot->dq_dqb with inode->i_blocks, i_bytes.
- * i_blocks and i_bytes updates itself are guarded by i_lock acquired directly
- * in inode_add_bytes() and inode_sub_bytes(). dq_state_lock protects
- * modifications of quota state (on quotaon and quotaoff) and readers who care
- * about latest values take it as well.
+ * dq_data_lock protects data from dq_dqb and also mem_dqinfo structures.
+ * dq_state_lock protects modifications of quota state (on quotaon and quotaoff)
+ * and readers who care about latest values take it as well.
  *
- * The spinlock ordering is hence: dq_data_lock > dq_list_lock > i_lock,
+ * The spinlock ordering is hence: i_lock > dq_data_lock > dq_list_lock,
  *   dq_list_lock > dq_state_lock
  *
  * Note that some things (eg. sb pointer, type, id) doesn't change during
  * the life of the dquot structure and so needn't to be protected by a lock
  *
- * Any operation working on dquots via inode pointers must hold dqptr_sem.  If
- * operation is just reading pointers from inode (or not using them at all) the
- * read lock is enough. If pointers are altered function must hold write lock
+ * Any operation working on dquots via inode pointers must hold i_lock.
  * (these locking rules also apply for S_NOQUOTA flag in the inode - note that
  * for altering the flag i_mutex is also needed).
  *
@@ -112,15 +107,8 @@
  * spinlock to internal buffers before writing.
  *
  * Lock ordering (including related VFS locks) is the following:
- *   i_mutex > dqonoff_sem > journal_lock > dqptr_sem > dquot->dq_lock >
- *   dqio_mutex
- * The lock ordering of dqptr_sem imposed by quota code is only dqonoff_sem >
- * dqptr_sem. But filesystem has to count with the fact that functions such as
- * dquot_alloc_space() acquire dqptr_sem and they usually have to be called
- * from inside a transaction to keep filesystem consistency after a crash. Also
- * filesystems usually want to do some IO on dquot from ->mark_dirty which is
- * called with dqptr_sem held.
- * i_mutex on quota files is special (it's below dqio_mutex)
+ *  i_mutex > dqonoff_sem > journal_lock > dquot->dq_lock > dqio_mutex
+ *  i_mutex on quota files is special (it's below dqio_mutex)
  */
 
 static __cacheline_aligned_in_smp DEFINE_SPINLOCK(dq_list_lock);
@@ -313,6 +301,25 @@
 {
 	return dquot->dq_sb->dq_op->mark_dirty(dquot);
 }
+/*
+ * i_lock is held before entry, but ->mark_dirty may sleep, take refcount
+ * before calling.
+ */
+static inline int inode_mark_dquot_dirty(struct inode *inode,
+					 struct dquot *dquot)
+{
+	int ret;
+
+	atomic_inc(&dquot->dq_count);
+	spin_unlock(&inode->i_lock);
+
+	ret = mark_dquot_dirty(dquot);
+	dqput(dquot);
+
+	spin_lock(&inode->i_lock);
+
+	return ret;
+}
 
 int dquot_mark_dquot_dirty(struct dquot *dquot)
 {
@@ -868,7 +875,6 @@
 /*
  * Remove references to dquots from inode and add dquot to list for freeing
  * if we have the last referece to dquot
- * We can't race with anybody because we hold dqptr_sem for writing...
  */
 static int remove_inode_dquot_ref(struct inode *inode, int type,
 				  struct list_head *tofree_head)
@@ -926,10 +932,12 @@
 		 *  We have to scan also I_NEW inodes because they can already
 		 *  have quota pointer initialized. Luckily, we need to touch
 		 *  only quota pointers and these have separate locking
-		 *  (dqptr_sem).
+		 *  (i_lock).
 		 */
+		spin_lock(&inode->i_lock);
 		if (!IS_NOQUOTA(inode))
 			remove_inode_dquot_ref(inode, type, tofree_head);
+		spin_unlock(&inode->i_lock);
 	}
 	spin_unlock(&inode_lock);
 }
@@ -940,9 +948,7 @@
 	LIST_HEAD(tofree_head);
 
 	if (sb->dq_op) {
-		down_write(&sb_dqopt(sb)->dqptr_sem);
 		remove_dquot_ref(sb, type, &tofree_head);
-		up_write(&sb_dqopt(sb)->dqptr_sem);
 		put_dquot_list(&tofree_head);
 	}
 }
@@ -1239,8 +1245,6 @@
 
 /*
  *	Initialize quota pointers in inode
- *	We do things in a bit complicated way but by that we avoid calling
- *	dqget() and thus filesystem callbacks under dqptr_sem.
  */
 int dquot_initialize(struct inode *inode, int type)
 {
@@ -1270,8 +1274,7 @@
 		got[cnt] = dqget(sb, id, cnt);
 	}
 
-	down_write(&sb_dqopt(sb)->dqptr_sem);
-	/* Having dqptr_sem we know NOQUOTA flags can't be altered... */
+	spin_lock(&inode->i_lock);
 	if (IS_NOQUOTA(inode))
 		goto out_err;
 	for (cnt = 0; cnt < MAXQUOTAS; cnt++) {
@@ -1293,7 +1296,8 @@
 		}
 	}
 out_err:
-	up_write(&sb_dqopt(sb)->dqptr_sem);
+	spin_unlock(&inode->i_lock);
+
 	/* Drop unused references */
 	for (cnt = 0; cnt < MAXQUOTAS; cnt++)
 		dqput(got[cnt]);
@@ -1309,12 +1313,12 @@
 	int cnt;
 	struct dquot *put[MAXQUOTAS];
 
-	down_write(&sb_dqopt(inode->i_sb)->dqptr_sem);
+	spin_lock(&inode->i_lock);
 	for (cnt = 0; cnt < MAXQUOTAS; cnt++) {
 		put[cnt] = inode->i_dquot[cnt];
 		inode->i_dquot[cnt] = NULL;
 	}
-	up_write(&sb_dqopt(inode->i_sb)->dqptr_sem);
+	spin_unlock(&inode->i_lock);
 
 	for (cnt = 0; cnt < MAXQUOTAS; cnt++)
 		dqput(put[cnt]);
@@ -1346,7 +1350,7 @@
 EXPORT_SYMBOL(vfs_dq_drop);
 
 /*
- * inode_reserved_space is managed internally by quota, and protected by
+ * inode_reserved_space is managed internally by quota, and is protected by
  * i_lock similar to i_blocks+i_bytes.
  */
 static qsize_t *inode_reserved_space(struct inode * inode)
@@ -1357,27 +1361,42 @@
 	return inode->i_sb->dq_op->get_reserved_space(inode);
 }
 
+static inline void __inode_add_rsv_space(struct inode *inode, qsize_t number)
+{
+	*inode_reserved_space(inode) += number;
+}
+
 void inode_add_rsv_space(struct inode *inode, qsize_t number)
 {
 	spin_lock(&inode->i_lock);
-	*inode_reserved_space(inode) += number;
+	__inode_add_rsv_space(inode, number);
 	spin_unlock(&inode->i_lock);
 }
 EXPORT_SYMBOL(inode_add_rsv_space);
 
-void inode_claim_rsv_space(struct inode *inode, qsize_t number)
+static inline void __inode_claim_rsv_space(struct inode *inode, qsize_t number)
 {
-	spin_lock(&inode->i_lock);
 	*inode_reserved_space(inode) -= number;
 	__inode_add_bytes(inode, number);
+}
+
+void inode_claim_rsv_space(struct inode *inode, qsize_t number)
+{
+	spin_lock(&inode->i_lock);
+	__inode_claim_rsv_space(inode, number);
 	spin_unlock(&inode->i_lock);
 }
 EXPORT_SYMBOL(inode_claim_rsv_space);
 
+static inline void __inode_sub_rsv_space(struct inode *inode, qsize_t number)
+{
+	*inode_reserved_space(inode) -= number;
+}
+
 void inode_sub_rsv_space(struct inode *inode, qsize_t number)
 {
 	spin_lock(&inode->i_lock);
-	*inode_reserved_space(inode) -= number;
+	__inode_sub_rsv_space(inode, number);
 	spin_unlock(&inode->i_lock);
 }
 EXPORT_SYMBOL(inode_sub_rsv_space);
@@ -1388,9 +1407,8 @@
 
 	if (!inode->i_sb->dq_op->get_reserved_space)
 		return 0;
-	spin_lock(&inode->i_lock);
+
 	ret = *inode_reserved_space(inode);
-	spin_unlock(&inode->i_lock);
 	return ret;
 }
 
@@ -1398,17 +1416,17 @@
 				int reserve)
 {
 	if (reserve)
-		inode_add_rsv_space(inode, number);
+		__inode_add_rsv_space(inode, number);
 	else
-		inode_add_bytes(inode, number);
+		__inode_add_bytes(inode, number);
 }
 
 static void inode_decr_space(struct inode *inode, qsize_t number, int reserve)
 {
 	if (reserve)
-		inode_sub_rsv_space(inode, number);
+		__inode_sub_rsv_space(inode, number);
 	else
-		inode_sub_bytes(inode, number);
+		__inode_sub_bytes(inode, number);
 }
 
 /*
@@ -1440,7 +1458,7 @@
 		goto out;
 	}
 
-	down_read(&sb_dqopt(inode->i_sb)->dqptr_sem);
+	spin_lock(&inode->i_lock);
 	if (IS_NOQUOTA(inode)) {
 		inode_incr_space(inode, number, reserve);
 		goto out_unlock;
@@ -1476,11 +1494,11 @@
 	/* Dirtify all the dquots - this can block when journalling */
 	for (cnt = 0; cnt < MAXQUOTAS; cnt++)
 		if (inode->i_dquot[cnt])
-			mark_dquot_dirty(inode->i_dquot[cnt]);
+			inode_mark_dquot_dirty(inode, inode->i_dquot[cnt]);
 out_flush_warn:
 	flush_warnings(inode->i_dquot, warntype);
 out_unlock:
-	up_read(&sb_dqopt(inode->i_sb)->dqptr_sem);
+	spin_unlock(&inode->i_lock);
 out:
 	return ret;
 }
@@ -1515,9 +1533,9 @@
 		return QUOTA_OK;
 	for (cnt = 0; cnt < MAXQUOTAS; cnt++)
 		warntype[cnt] = QUOTA_NL_NOWARN;
-	down_read(&sb_dqopt(inode->i_sb)->dqptr_sem);
+	spin_lock(&((struct inode *)inode)->i_lock);
 	if (IS_NOQUOTA(inode)) {
-		up_read(&sb_dqopt(inode->i_sb)->dqptr_sem);
+		spin_unlock(&((struct inode *)inode)->i_lock);
 		return QUOTA_OK;
 	}
 	spin_lock(&dq_data_lock);
@@ -1541,9 +1559,10 @@
 		/* Dirtify all the dquots - this can block when journalling */
 		for (cnt = 0; cnt < MAXQUOTAS; cnt++)
 			if (inode->i_dquot[cnt])
-				mark_dquot_dirty(inode->i_dquot[cnt]);
+				inode_mark_dquot_dirty((struct inode *)inode,
+						       inode->i_dquot[cnt]);
 	flush_warnings(inode->i_dquot, warntype);
-	up_read(&sb_dqopt(inode->i_sb)->dqptr_sem);
+	spin_unlock(&((struct inode *)inode)->i_lock);
 	return ret;
 }
 EXPORT_SYMBOL(dquot_alloc_inode);
@@ -1558,10 +1577,10 @@
 		goto out;
 	}
 
-	down_read(&sb_dqopt(inode->i_sb)->dqptr_sem);
+	spin_lock(&inode->i_lock);
 	if (IS_NOQUOTA(inode))	{
-		up_read(&sb_dqopt(inode->i_sb)->dqptr_sem);
-		inode_claim_rsv_space(inode, number);
+		__inode_claim_rsv_space(inode, number);
+		spin_unlock(&inode->i_lock);
 		goto out;
 	}
 
@@ -1573,13 +1592,13 @@
 							number);
 	}
 	/* Update inode bytes */
-	inode_claim_rsv_space(inode, number);
+	__inode_claim_rsv_space(inode, number);
 	spin_unlock(&dq_data_lock);
 	/* Dirtify all the dquots - this can block when journalling */
 	for (cnt = 0; cnt < MAXQUOTAS; cnt++)
 		if (inode->i_dquot[cnt])
-			mark_dquot_dirty(inode->i_dquot[cnt]);
-	up_read(&sb_dqopt(inode->i_sb)->dqptr_sem);
+			inode_mark_dquot_dirty(inode, inode->i_dquot[cnt]);
+	spin_unlock(&inode->i_lock);
 out:
 	return ret;
 }
@@ -1602,10 +1621,9 @@
 		return QUOTA_OK;
 	}
 
-	down_read(&sb_dqopt(inode->i_sb)->dqptr_sem);
-	/* Now recheck reliably when holding dqptr_sem */
+	spin_lock(&inode->i_lock);
 	if (IS_NOQUOTA(inode)) {
-		up_read(&sb_dqopt(inode->i_sb)->dqptr_sem);
+		spin_unlock(&inode->i_lock);
 		goto out_sub;
 	}
 	spin_lock(&dq_data_lock);
@@ -1626,10 +1644,10 @@
 	/* Dirtify all the dquots - this can block when journalling */
 	for (cnt = 0; cnt < MAXQUOTAS; cnt++)
 		if (inode->i_dquot[cnt])
-			mark_dquot_dirty(inode->i_dquot[cnt]);
+			inode_mark_dquot_dirty(inode, inode->i_dquot[cnt]);
 out_unlock:
 	flush_warnings(inode->i_dquot, warntype);
-	up_read(&sb_dqopt(inode->i_sb)->dqptr_sem);
+	spin_unlock(&inode->i_lock);
 	return QUOTA_OK;
 }
 
@@ -1662,10 +1680,9 @@
 	if (IS_NOQUOTA(inode))
 		return QUOTA_OK;
 
-	down_read(&sb_dqopt(inode->i_sb)->dqptr_sem);
-	/* Now recheck reliably when holding dqptr_sem */
+	spin_lock(&((struct inode *)inode)->i_lock);
 	if (IS_NOQUOTA(inode)) {
-		up_read(&sb_dqopt(inode->i_sb)->dqptr_sem);
+		spin_unlock(&((struct inode *)inode)->i_lock);
 		return QUOTA_OK;
 	}
 	spin_lock(&dq_data_lock);
@@ -1679,9 +1696,9 @@
 	/* Dirtify all the dquots - this can block when journalling */
 	for (cnt = 0; cnt < MAXQUOTAS; cnt++)
 		if (inode->i_dquot[cnt])
-			mark_dquot_dirty(inode->i_dquot[cnt]);
+			inode_mark_dquot_dirty((struct inode *)inode, inode->i_dquot[cnt]);
 	flush_warnings(inode->i_dquot, warntype);
-	up_read(&sb_dqopt(inode->i_sb)->dqptr_sem);
+	spin_unlock(&((struct inode *)inode)->i_lock);
 	return QUOTA_OK;
 }
 EXPORT_SYMBOL(dquot_free_inode);
@@ -1721,14 +1738,13 @@
 		transfer_to[GRPQUOTA] = dqget(inode->i_sb, iattr->ia_gid,
 					      GRPQUOTA);
 
-	down_write(&sb_dqopt(inode->i_sb)->dqptr_sem);
-	/* Now recheck reliably when holding dqptr_sem */
+	spin_lock(&inode->i_lock);
 	if (IS_NOQUOTA(inode)) {	/* File without quota accounting? */
-		up_write(&sb_dqopt(inode->i_sb)->dqptr_sem);
+		spin_unlock(&inode->i_lock);
 		goto put_all;
 	}
 	spin_lock(&dq_data_lock);
-	cur_space = inode_get_bytes(inode);
+	cur_space = __inode_get_bytes(inode);
 	rsv_space = inode_get_rsv_space(inode);
 	space = cur_space + rsv_space;
 	/* Build the transfer_from list and check the limits */
@@ -1771,7 +1787,7 @@
 		inode->i_dquot[cnt] = transfer_to[cnt];
 	}
 	spin_unlock(&dq_data_lock);
-	up_write(&sb_dqopt(inode->i_sb)->dqptr_sem);
+	spin_unlock(&inode->i_lock);
 
 	/* Dirtify all the dquots - this can block when journalling */
 	for (cnt = 0; cnt < MAXQUOTAS; cnt++) {
@@ -1795,7 +1811,7 @@
 	return ret;
 over_quota:
 	spin_unlock(&dq_data_lock);
-	up_write(&sb_dqopt(inode->i_sb)->dqptr_sem);
+	spin_unlock(&inode->i_lock);
 	/* Clear dquot pointers we don't want to dqput() */
 	for (cnt = 0; cnt < MAXQUOTAS; cnt++)
 		transfer_from[cnt] = NULL;
@@ -2047,13 +2063,13 @@
 		/* We don't want quota and atime on quota files (deadlocks
 		 * possible) Also nobody should write to the file - we use
 		 * special IO operations which ignore the immutable bit. */
-		down_write(&dqopt->dqptr_sem);
 		mutex_lock_nested(&inode->i_mutex, I_MUTEX_QUOTA);
+		spin_lock(&inode->i_lock);
 		oldflags = inode->i_flags & (S_NOATIME | S_IMMUTABLE |
 					     S_NOQUOTA);
 		inode->i_flags |= S_NOQUOTA | S_NOATIME | S_IMMUTABLE;
+		spin_unlock(&inode->i_lock);
 		mutex_unlock(&inode->i_mutex);
-		up_write(&dqopt->dqptr_sem);
 		sb->dq_op->drop(inode);
 	}
 
@@ -2090,14 +2106,14 @@
 	iput(inode);
 out_lock:
 	if (oldflags != -1) {
-		down_write(&dqopt->dqptr_sem);
 		mutex_lock_nested(&inode->i_mutex, I_MUTEX_QUOTA);
+		spin_lock(&inode->i_lock);
 		/* Set the flags back (in the case of accidental quotaon()
 		 * on a wrong file we don't want to mess up the flags) */
 		inode->i_flags &= ~(S_NOATIME | S_NOQUOTA | S_IMMUTABLE);
 		inode->i_flags |= oldflags;
+		spin_unlock(&inode->i_lock);
 		mutex_unlock(&inode->i_mutex);
-		up_write(&dqopt->dqptr_sem);
 	}
 	mutex_unlock(&dqopt->dqonoff_mutex);
 out_fmt:
--- linux-2.6.32-279.el6.x86_64/fs/quota/quota.c	2012-06-14 05:41:12.000000000 +0800
+++ linux-2.6.32-279.el6.x86_64.quota/fs/quota/quota.c	2013-02-20 14:58:41.155761832 +0800
@@ -257,13 +257,13 @@
 		case Q_GETFMT: {
 			__u32 fmt;
 
-			down_read(&sb_dqopt(sb)->dqptr_sem);
+			mutex_lock(&sb_dqopt(sb)->dqonoff_mutex);
 			if (!sb_has_quota_active(sb, type)) {
-				up_read(&sb_dqopt(sb)->dqptr_sem);
+				mutex_unlock(&sb_dqopt(sb)->dqonoff_mutex);
 				return -ESRCH;
 			}
 			fmt = sb_dqopt(sb)->info[type].dqi_format->qf_fmt_id;
-			up_read(&sb_dqopt(sb)->dqptr_sem);
+			mutex_unlock(&sb_dqopt(sb)->dqonoff_mutex);
 			if (copy_to_user(addr, &fmt, sizeof(fmt)))
 				return -EFAULT;
 			return 0;
--- linux-2.6.32-279.el6.x86_64/fs/super.c	2012-06-14 05:41:12.000000000 +0800
+++ linux-2.6.32-279.el6.x86_64.quota/fs/super.c	2013-02-20 14:58:41.155761832 +0800
@@ -97,7 +97,6 @@
 		mutex_init(&s->s_vfs_rename_mutex);
 		mutex_init(&s->s_dquot.dqio_mutex);
 		mutex_init(&s->s_dquot.dqonoff_mutex);
-		init_rwsem(&s->s_dquot.dqptr_sem);
 		init_waitqueue_head(&s->s_wait_unfrozen);
 		s->s_maxbytes = MAX_NON_LFS;
 		s->dq_op = sb_dquot_ops;
--- linux-2.6.32-279.el6.x86_64/include/linux/fs.h	2012-06-14 05:41:19.000000000 +0800
+++ linux-2.6.32-279.el6.x86_64.quota/include/linux/fs.h	2013-02-21 14:01:51.328386258 +0800
@@ -2396,7 +2396,9 @@
 extern int vfs_getattr(struct vfsmount *, struct dentry *, struct kstat *);
 void __inode_add_bytes(struct inode *inode, loff_t bytes);
 void inode_add_bytes(struct inode *inode, loff_t bytes);
+void __inode_sub_bytes(struct inode *inode, loff_t bytes);
 void inode_sub_bytes(struct inode *inode, loff_t bytes);
+loff_t __inode_get_bytes(struct inode *inode);
 loff_t inode_get_bytes(struct inode *inode);
 void inode_set_bytes(struct inode *inode, loff_t bytes);
 
--- linux-2.6.32-279.el6.x86_64/fs/stat.c	2012-06-14 05:41:12.000000000 +0800
+++ linux-2.6.32-279.el6.x86_64.quota/fs/stat.c	2013-02-21 17:16:30.047480784 +0800
@@ -422,9 +422,8 @@
 
 EXPORT_SYMBOL(inode_add_bytes);
 
-void inode_sub_bytes(struct inode *inode, loff_t bytes)
+void __inode_sub_bytes(struct inode *inode, loff_t bytes)
 {
-	spin_lock(&inode->i_lock);
 	inode->i_blocks -= bytes >> 9;
 	bytes &= 511;
 	if (inode->i_bytes < bytes) {
@@ -432,17 +431,27 @@
 		inode->i_bytes += 512;
 	}
 	inode->i_bytes -= bytes;
+}
+
+void inode_sub_bytes(struct inode *inode, loff_t bytes)
+{
+	spin_lock(&inode->i_lock);
+	__inode_sub_bytes(inode, bytes);
 	spin_unlock(&inode->i_lock);
 }
 
 EXPORT_SYMBOL(inode_sub_bytes);
 
+loff_t __inode_get_bytes(struct inode *inode)
+{
+	return (((loff_t)inode->i_blocks) << 9) + inode->i_bytes;
+}
 loff_t inode_get_bytes(struct inode *inode)
 {
 	loff_t ret;
 
 	spin_lock(&inode->i_lock);
-	ret = (((loff_t)inode->i_blocks) << 9) + inode->i_bytes;
+	ret = __inode_get_bytes(inode);
 	spin_unlock(&inode->i_lock);
 	return ret;
 }
